import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

def evaluate_model(y_train=None, y_train_pred=None, 
                   y_val=None, y_val_pred=None, 
                   y_test=None, y_test_pred=None, 
                   group_by=False):
    """
    Computes R², MAE, RMSE, Count, and Predicted Mean/Actual Mean ratio for 
    Train, Validation, and Test sets.
    Allows grouping metrics based on given bins.
    
    Parameters:
    y_train (array-like, optional): True values for training set
    y_train_pred (array-like, optional): Predicted values for training set
    y_val (array-like, optional): True values for validation set
    y_val_pred (array-like, optional): Predicted values for validation set
    y_test (array-like, optional): True values for test set
    y_test_pred (array-like, optional): Predicted values for test set
    group_by (bool, optional): Whether to compute metrics per bin. Default is False.
    
    Returns:
    pd.DataFrame: Metrics summary
    (Optional) pd.DataFrame: Grouped metrics if `group_by=True`
    """
    
    def compute_metrics(y_true, y_pred):
        """Helper function to compute metrics after flattening"""
        y_true = np.array(y_true).ravel()  # Convert to 1D
        y_pred = np.array(y_pred).ravel()  # Convert to 1D
        
        if len(y_true) == 0 or len(y_pred) == 0:  # Ensure no empty arrays
            return np.nan, np.nan, np.nan, 0, np.nan
        
        r2 = r2_score(y_true, y_pred)
        mae = mean_absolute_error(y_true, y_pred)
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
        count = len(y_true)
        
        actual_mean = np.mean(y_true)
        pred_mean = np.mean(y_pred)
        # Avoid division by zero
        ratio = pred_mean / actual_mean if actual_mean != 0 else np.nan
        
        return r2, mae, rmse, count, ratio

    results = {
        "Set": [],
        "R²": [],
        "MAE": [],
        "RMSE": [],
        "Count": [],
        "Y_Pred_Mean/Actual_Mean": []
    }

    # Check which datasets are provided
    datasets = {
        "Train": (y_train, y_train_pred),
        "Validation": (y_val, y_val_pred),
        "Test": (y_test, y_test_pred)
    }

    for name, (y_true, y_pred) in datasets.items():
        if y_true is not None and y_pred is not None:
            r2, mae, rmse, count, ratio = compute_metrics(y_true, y_pred)
            results["Set"].append(name)
            results["R²"].append(r2)
            results["MAE"].append(mae)
            results["RMSE"].append(rmse)
            results["Count"].append(count)
            results["Y_Pred_Mean/Actual_Mean"].append(ratio)

    df_results = pd.DataFrame(results)

    # Grouping if enabled and data exists
    if group_by:
        group_labels = ["0", "1-3", "3-7", "7-15", "15+"]
        bins = [-np.inf, 0, 3, 7, 15, np.inf]
        
        grouped_results = []
        
        for name, (y_true, y_pred) in datasets.items():
            if y_true is not None and y_pred is not None:
                y_true = np.array(y_true).ravel()  # Convert to 1D
                y_pred = np.array(y_pred).ravel()  # Convert to 1D
                
                df = pd.DataFrame({"y_true": y_true, "y_pred": y_pred})
                df["Group"] = pd.cut(df["y_true"], bins=bins, labels=group_labels)
                
                df = df.dropna(subset=["Group"])  # Drop rows where the group is NaN
                
                if df.empty:  # Skip if all data was dropped
                    continue
                
                # Compute grouped metrics per bin
                grouped_metrics = df.groupby("Group").apply(lambda g: compute_metrics(g["y_true"], g["y_pred"]))
                
                # Convert tuple to DataFrame with new column names
                grouped_metrics = grouped_metrics.apply(
                    pd.Series, 
                    index=["R²", "MAE", "RMSE", "Count", "Y_Pred_Mean/Actual_Mean"]
                )
                
                # Ensure that all bins in group_labels are present; fill missing bins
                grouped_metrics = grouped_metrics.reindex(group_labels)
                grouped_metrics["Count"] = grouped_metrics["Count"].fillna(0)
                
                # Add a column for the dataset name
                grouped_metrics["Set"] = name
                
                grouped_results.append(grouped_metrics)
        
        if grouped_results:
            df_grouped = pd.concat(grouped_results).reset_index().rename(columns={"index": "Bin"})
            return df_results, df_grouped
    
    return df_results

# Example usage:
# Suppose you have arrays y_train, y_train_pred, etc.
# df_overall, df_grouped = evaluate_model(y_train, y_train_pred, y_val, y_val_pred, y_test, y_test_pred, group_by=True)
# print(df_overall)
# print(df_grouped)



