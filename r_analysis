import numpy as np
import pandas as pd
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

def evaluate_model(y_train=None, y_train_pred=None, 
                   y_val=None, y_val_pred=None, 
                   y_test=None, y_test_pred=None, 
                   group_by=False):
    """
    Computes R², MAE, RMSE, and Count for Train, Validation, and Test sets.
    Allows grouping metrics based on given bins.
    
    Parameters:
    y_train (array-like, optional): True values for training set
    y_train_pred (array-like, optional): Predicted values for training set
    y_val (array-like, optional): True values for validation set
    y_val_pred (array-like, optional): Predicted values for validation set
    y_test (array-like, optional): True values for test set
    y_test_pred (array-like, optional): Predicted values for test set
    group_by (bool, optional): Whether to compute metrics per bin. Default is False.
    
    Returns:
    pd.DataFrame: Metrics summary
    (Optional) pd.DataFrame: Grouped metrics if `group_by=True`
    """
    
    def compute_metrics(y_true, y_pred):
        """Helper function to compute metrics after flattening"""
        y_true = np.array(y_true).ravel()  # Convert to 1D
        y_pred = np.array(y_pred).ravel()  # Convert to 1D
        
        if len(y_true) == 0 or len(y_pred) == 0:  # Ensure no empty arrays
            return np.nan, np.nan, np.nan, 0
        
        r2 = r2_score(y_true, y_pred)
        mae = mean_absolute_error(y_true, y_pred)
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
        count = len(y_true)
        return r2, mae, rmse, count

    results = {
        "Set": [],
        "R²": [],
        "MAE": [],
        "RMSE": [],
        "Count": []
    }

    # Check which datasets are provided
    datasets = {
        "Train": (y_train, y_train_pred),
        "Validation": (y_val, y_val_pred),
        "Test": (y_test, y_test_pred)
    }

    for name, (y_true, y_pred) in datasets.items():
        if y_true is not None and y_pred is not None:
            r2, mae, rmse, count = compute_metrics(y_true, y_pred)
            results["Set"].append(name)
            results["R²"].append(r2)
            results["MAE"].append(mae)
            results["RMSE"].append(rmse)
            results["Count"].append(count)

    df_results = pd.DataFrame(results)

    # Grouping if enabled and data exists
    if group_by:
        group_labels = ["0", "1-3", "3-7", "7-15", "15+"]
        bins = [-np.inf, 0, 3, 7, 15, np.inf]
        
        grouped_results = []
        
        for name, (y_true, y_pred) in datasets.items():
            if y_true is not None and y_pred is not None:
                y_true = np.array(y_true).ravel()  # Convert to 1D
                y_pred = np.array(y_pred).ravel()  # Convert to 1D
                
                df = pd.DataFrame({"y_true": y_true, "y_pred": y_pred})
                df["Group"] = pd.cut(df["y_true"], bins=bins, labels=group_labels)
                
                df = df.dropna(subset=["Group"])  # Drop empty groups
                
                if df.empty:  # Skip if all data was dropped
                    continue
                
                # Compute grouped metrics
                grouped_metrics = df.groupby("Group").apply(lambda g: compute_metrics(g["y_true"], g["y_pred"]))
                
                # Convert tuple to DataFrame
                grouped_metrics = grouped_metrics.apply(pd.Series, index=["R²", "MAE", "RMSE", "Count"])
                grouped_metrics["Set"] = name
                grouped_results.append(grouped_metrics)
        
        if grouped_results:
            df_grouped = pd.concat(grouped_results).reset_index()
            df_grouped.rename(columns={"Group": "Bin"}, inplace=True)
            return df_results, df_grouped
    
    return df_results

